package tfidf;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.MultipleInputs;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;

import java.io.IOException;
import java.util.*;
public class JobB extends Configured implements Tool{

    @Override
    public int run(String[] args) throws Exception {
        Configuration conf = this.getConf();
        Job jobB = Job.getInstance(conf,"JobB");

        MultipleInputs.addInputPath(jobB,new Path(args[0]), TextInputFormat.class,JobA_output.class);
        MultipleInputs.addInputPath(jobB,new Path(args[1]), TextInputFormat.class,JoB1.class);

        jobB.setJarByClass(JobB.class);

        jobB.setReducerClass(summary.class);

        jobB.setMapOutputKeyClass(Text.class);
        jobB.setMapOutputValueClass(Text.class);

        jobB.setOutputKeyClass(Text.class);
        jobB.setOutputValueClass(Text.class);
        FileOutputFormat.setOutputPath(jobB, new Path(args[2]));


        return (jobB.waitForCompletion(true) ? 0 : 1);
    }
    public static void main(String[] args) throws Exception {
        int res = ToolRunner.run(new Configuration(), new JobB(), args);
        System.exit(res);
    }

    public static class JobA_output extends Mapper<Object, Text,Text,Text>{

        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
            String [] info = value.toString().split("\t");
            context.write(new Text(info[0]),new Text("A" + "\t"  + info[1] + "\t" + info[2])); //<(DocID)(A, unigram, TF-IDF)>
        }
    }

    public static class JoB1 extends Mapper<Object, Text,Text,Text>{

        public void map(Object key, Text value, Context context) throws IOException,InterruptedException{
            if (!value.toString().isEmpty()) {
                if (value.toString().split("<====>").length > 2) {
                    String articles = value.toString().split("<====>")[2].replaceAll("[^A-Za-z0-9 ]", "").toLowerCase();
                    String id = value.toString().split("<====>")[1];
                    context.write(new Text(id),new Text("B\t"+ articles)); // <(DocID),(B,sentence)>

                }
            }
        }
    }

    public static class summary extends Reducer<Text,Text, NullWritable,Text>{

        TreeMap< DoubleWritable, Text> map;
        public void setup(Context context) throws IOException,
                InterruptedException
        {
            map = new TreeMap<DoubleWritable, Text>();
        }
        public void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException{


            HashMap<String,Double> hashMap = new HashMap<String,Double>();
            ArrayList<String> strings = new ArrayList<String>();
            for(Text string: values){
                //strings = "A(0)  the(1)   1.0505(2)" mapper 1
                //string  = "B  This is the example"
                String[] s = string.toString().split("\t");
                if(s[0].charAt(0) == 'A'){
                    hashMap.put(key + "\t" +s[1], Double.parseDouble((s[2])));// (HashMap: key = DocumentID+unigram, value = TF-IDF value)
                }
                if(s[0].charAt(0) == 'B') {
                    String [] sentence = s[1].split("\\. ");
                    for (int i =0; i < sentence.length; i ++){
                        strings.add(sentence[i]);
                    }
                }
            }
            for(String b: strings){

                ArrayList<Double> sentence_value = new ArrayList<Double>();

                StringTokenizer itr = new StringTokenizer(b); //Thamesmead   is a suburb of south London in the London Boroughs of Greenwich and Bexley.

                while (itr.hasMoreTokens()){
                    String x = key.toString() + "\t" + itr.nextToken(); //DocID     Thamesmead
                    sentence_value.add(hashMap.get(x));
                }

                if(sentence_value.size()>5){

                    Comparator<Double> comparator = Collections.reverseOrder();
                    Collections.sort(sentence_value,comparator);
                    for(int i =4; i<sentence_value.size(); i ++){
                        sentence_value.remove(i);
                    }
                }
                double sentence_tf_idf =0;
                for(int i =0; i < sentence_value.size(); i++){
                    if(sentence_value.get(i) != null) {
                        sentence_tf_idf += sentence_value.get(i);
                    }
                }
                map.put(new DoubleWritable(sentence_tf_idf), new Text(b));
                if(map.size()>5){
                    map.remove(map.firstKey());
                }
            }
            for (Map.Entry<DoubleWritable, Text> entry : map.entrySet())
            {
                context.write(NullWritable.get(),entry.getValue());
            }

        }


    }


}
